{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wait for fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Step 1. Data analysis and preprocessing\n",
    "\n",
    "> Step 2. Model selection\n",
    "\n",
    "> Step 3. Model training\n",
    "\n",
    "> Step 4. Model evaluation\n",
    "\n",
    "> Step 5. Model prediction\n",
    "\n",
    "> Step 6. Model submission\n",
    "\n",
    "> Step 7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the necessary libraries section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python library\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle as pkl\n",
    "import glob\n",
    "\n",
    "import yaml\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Sklearn library\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Pytorch library\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import models,transforms\n",
    "\n",
    "# CV2 library\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project name:  Cancer Detection\n",
      "Project version:  DPL302m Project - Fall 2024 of Group 1\n",
      "Project author:  1.0.0\n",
      "Data path:  {'data_path': 'data/', 'csv_path': 'data/HAM10000_metadata.csv', 'images_path': 'data/images/'}\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "with open('config.yaml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "# Project information\n",
    "print('Project name: ', config['project']['name'])\n",
    "print('Project version: ', config['project']['description'])\n",
    "print('Project author: ', config['project']['version'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path:  {'data_path': 'data/', 'csv_path': 'data/HAM10000_metadata.csv', 'images_path': 'data/images/'}\n",
      "Number of images:  10015\n"
     ]
    }
   ],
   "source": [
    "# Data location\n",
    "print('Data path: ', config['data'])\n",
    "data_path = config['data']['data_path']\n",
    "csv_path = config['data']['csv_path']\n",
    "images_path = config['data']['images_path']\n",
    "\n",
    "# Data reading\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "# Create a dictionary for images location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types:\n",
      "lesion_id       object\n",
      "image_id        object\n",
      "dx              object\n",
      "dx_type         object\n",
      "age              int32\n",
      "sex             object\n",
      "localization    object\n",
      "dtype: object\n",
      "\n",
      "Unique values for each column:\n",
      "dx ['bkl' 'nv' 'df' 'mel' 'vasc' 'bcc' 'akiec']\n",
      "dx_type ['histo' 'consensus' 'confocal' 'follow_up']\n",
      "age [80 75 60 70 55 85 65 40 50 45 35  0 30  5 25 20 10 15]\n",
      "sex ['male' 'female']\n",
      "localization ['scalp' 'ear' 'face' 'back' 'trunk' 'chest' 'upper extremity' 'abdomen'\n",
      " 'lower extremity' 'genital' 'neck' 'hand' 'foot' 'acral']\n",
      "\n",
      "Nan values in each column:\n",
      "lesion_id 0\n",
      "image_id 0\n",
      "dx 0\n",
      "dx_type 0\n",
      "age 0\n",
      "sex 0\n",
      "localization 0\n",
      "\n",
      "Unknown values in each column:\n",
      "lesion_id 0\n",
      "image_id 0\n",
      "dx 0\n",
      "dx_type 0\n",
      "age 0\n",
      "sex 0\n",
      "localization 0\n"
     ]
    }
   ],
   "source": [
    "def data_check(data):\n",
    "    # Show data types\n",
    "    print('Data types:')\n",
    "    print(data.dtypes)\n",
    "    print()\n",
    "    # Show unique values for each column\n",
    "    print('Unique values for each column:')\n",
    "    for col in data.columns:\n",
    "        if col == 'image_id' or col == 'lesion_id':\n",
    "            continue\n",
    "        print(col, data[col].unique())\n",
    "    print()\n",
    "    # Count nan values\n",
    "    print('Nan values in each column:')\n",
    "    for col in data.columns:\n",
    "        print(col, data[col].isnull().sum())\n",
    "    print()\n",
    "    # Count unknown values\n",
    "    print('Unknown values in each column:')\n",
    "    for col in data.columns:\n",
    "        print(col, data[data[col] == 'unknown'].shape[0])\n",
    "\n",
    "data_check(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after cleaning:\n",
      "Data types:\n",
      "lesion_id            object\n",
      "image_id             object\n",
      "dx                   object\n",
      "dx_type              object\n",
      "age                   int32\n",
      "sex                  object\n",
      "localization         object\n",
      "dx_code               int32\n",
      "dx_type_code          int32\n",
      "sex_code              int32\n",
      "localization_code     int32\n",
      "dtype: object\n",
      "\n",
      "Unique values for each column:\n",
      "dx ['bkl' 'nv' 'df' 'mel' 'vasc' 'bcc' 'akiec']\n",
      "dx_type ['histo' 'consensus' 'confocal' 'follow_up']\n",
      "age [80 75 60 70 55 85 65 40 50 45 35  0 30  5 25 20 10 15]\n",
      "sex ['male' 'female']\n",
      "localization ['scalp' 'ear' 'face' 'back' 'trunk' 'chest' 'upper extremity' 'abdomen'\n",
      " 'lower extremity' 'genital' 'neck' 'hand' 'foot' 'acral']\n",
      "dx_code [2 5 3 4 6 1 0]\n",
      "dx_type_code [3 1 0 2]\n",
      "sex_code [1 0]\n",
      "localization_code [11  4  5  2 12  3 13  0  9  7 10  8  6  1]\n",
      "\n",
      "Nan values in each column:\n",
      "lesion_id 0\n",
      "image_id 0\n",
      "dx 0\n",
      "dx_type 0\n",
      "age 0\n",
      "sex 0\n",
      "localization 0\n",
      "dx_code 0\n",
      "dx_type_code 0\n",
      "sex_code 0\n",
      "localization_code 0\n",
      "\n",
      "Unknown values in each column:\n",
      "lesion_id 0\n",
      "image_id 0\n",
      "dx 0\n",
      "dx_type 0\n",
      "age 0\n",
      "sex 0\n",
      "localization 0\n",
      "dx_code 0\n",
      "dx_type_code 0\n",
      "sex_code 0\n",
      "localization_code 0\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates for image_id and lesion_id\n",
    "data = data.drop_duplicates(subset=['image_id', 'lesion_id'])\n",
    "\n",
    "# Drop nan and \"unknown\" values\n",
    "data = data.dropna()\n",
    "data = data[data['age'] != 'unknown']\n",
    "data = data[data['sex'] != 'unknown']\n",
    "data = data[data['localization'] != 'unknown']\n",
    "\n",
    "# Convert age to int\n",
    "data['age'] = data['age'].astype(int)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "data['dx_code'] = label_encoder.fit_transform(data['dx'])\n",
    "data['dx_type_code'] = label_encoder.fit_transform(data['dx_type'])\n",
    "data['sex_code'] = label_encoder.fit_transform(data['sex'])\n",
    "data['localization_code'] = label_encoder.fit_transform(data['localization'])\n",
    "\n",
    "print('Data after cleaning:')\n",
    "data_check(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images:  9761\n"
     ]
    }
   ],
   "source": [
    "# Image loading\n",
    "def load_images(data, images_path):\n",
    "    images = []\n",
    "    for index, row in data.iterrows():\n",
    "        image_name = row['image_id'] + '.jpg'\n",
    "        image_path = os.path.join(images_path, image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print('Image not found: ', image_path)\n",
    "            continue\n",
    "        # image preprocessing\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        images.append(image)\n",
    "    return images\n",
    "\n",
    "# Load images\n",
    "images = load_images(data, images_path)\n",
    "# Print the number of images\n",
    "print('Number of images: ', len(images))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
