{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Google Colab\n"
     ]
    }
   ],
   "source": [
    "# Google Colab library\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    \n",
    "    print(\"In Google Colab\")\n",
    "except:\n",
    "    print(\"Not in Google Colab\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fxlqt\\.conda\\envs\\Py311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Python library\n",
    "import os\n",
    "import zipfile\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import multiprocessing\n",
    "import pickle as pkl\n",
    "import yaml\n",
    "import albumentations as A\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Sklearn library\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Pytorch library\n",
    "import torch\n",
    "\n",
    "from torch import optim, nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import models,transforms\n",
    "\n",
    "# CV2 library\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n",
      "Cuda version:  12.4\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device: \", device)\n",
    "print(\"Cuda version: \", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project name:  Cancer Detection\n",
      "Project version:  DPL302m Project - Fall 2024 of Group 1\n",
      "Project author:  Group 1\n",
      "Project version:  1.0.0\n",
      "Data path:  {'data_path': 'data/', 'raw_path': 'data/raw/', 'raw_csv_path': 'data/raw/HAM10000_metadata.csv', 'raw_images_path': 'data/raw/images/', 'processed_path': 'data/processed/', 'processed_images_path': 'data/processed/images/'}\n",
      "N workers:  8\n",
      "Batch size:  32\n",
      "Preprocessing configuration\n",
      "Augmentation ratios:  1\n",
      "Resize shape:  (32, 32)\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "with open('config.yaml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "# Project information\n",
    "print('Project name: ', config['project']['name'])\n",
    "print('Project version: ', config['project']['description'])\n",
    "print('Project author: ', config['project']['author'])\n",
    "print('Project version: ', config['project']['version'])\n",
    "\n",
    "# Data location\n",
    "print('Data path: ', config['data'])\n",
    "data_path = config['data']['raw_path']\n",
    "csv_path = config['data']['raw_csv_path']\n",
    "images_path = config['data']['raw_images_path']\n",
    "\n",
    "# Training configuration\n",
    "n_workers = config['hyperparameters']['n_workers']\n",
    "batch_size = config['hyperparameters']['batch_size']\n",
    "print('N workers: ', n_workers)\n",
    "print('Batch size: ', batch_size)\n",
    "\n",
    "# Preprocessing configuration\n",
    "print('Preprocessing configuration')\n",
    "augmentation_ratio = config['preprocessing']['augmentation']['ratio']\n",
    "resize_shape = tuple(config['preprocessing']['resize'])\n",
    "print('Augmentation ratios: ', augmentation_ratio)\n",
    "print('Resize shape: ', resize_shape)\n",
    "\n",
    "# Create a dictionary for images location\n",
    "lesion_type_dict = {\n",
    "    'nv': 'Melanocytic nevi',\n",
    "    'mel': 'Dermatofibroma',\n",
    "    'bkl': 'Benign keratosis-like lesions ',\n",
    "    'bcc': 'Basal cell carcinoma',\n",
    "    'akiec': 'Actinic keratoses',\n",
    "    'vasc': 'Vascular lesions',\n",
    "    'df': 'Dermatofibroma'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data shape: (10015, 7)\n",
      "Data shape: (10015, 7)\n",
      "\n",
      "Data types:\n",
      "lesion_id        object\n",
      "image_id         object\n",
      "dx               object\n",
      "dx_type          object\n",
      "age             float64\n",
      "sex              object\n",
      "localization     object\n",
      "dtype: object\n",
      "\n",
      "Unique values for each column:\n",
      "dx: ['mel' 'nv' 'bkl' 'bcc' 'akiec']...\n",
      "dx_type: ['histo' 'consensus' 'follow_up' 'confocal']...\n",
      "age: [65. 40. 35. 45. 55.]...\n",
      "sex: ['male' 'female' 'unknown']...\n",
      "localization: ['face' 'lower extremity' 'back' 'trunk' 'abdomen']...\n",
      "\n",
      "NaN values in each column:\n",
      "age    57\n",
      "dtype: int64\n",
      "\n",
      "Unknown values in each column:\n",
      "sex: 57\n",
      "localization: 234\n",
      "\n",
      "Summary of potential data issues:\n",
      "- Columns with NaN values: ['age']\n",
      "- Columns with 'unknown' values: ['sex', 'localization']\n",
      "Data after cleaning:\n",
      "        lesion_id                          image_id   dx    dx_type  age  \\\n",
      "1617  HAM_0007180  data/raw/images/ISIC_0033272.jpg  mel      histo   65   \n",
      "8128  HAM_0007195  data/raw/images/ISIC_0031923.jpg   nv      histo   40   \n",
      "2168  HAM_0001835  data/raw/images/ISIC_0026652.jpg  mel      histo   65   \n",
      "1090  HAM_0000465  data/raw/images/ISIC_0030583.jpg  bkl  consensus   35   \n",
      "7754  HAM_0001720  data/raw/images/ISIC_0034010.jpg   nv      histo   45   \n",
      "\n",
      "         sex     localization  dx_code  dx_type_code  sex_code  \n",
      "1617    male             face        4             3         1  \n",
      "8128  female  lower extremity        5             3         0  \n",
      "2168    male             back        4             3         1  \n",
      "1090  female            trunk        2             1         0  \n",
      "7754    male          abdomen        5             3         1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 244/244 [00:04<00:00, 49.15it/s]\n",
      "100%|██████████| 62/62 [00:01<00:00, 45.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dx_code  count\n",
      "5        5   5239\n",
      "4        4    858\n",
      "2        2    845\n",
      "1        1    410\n",
      "0        0    256\n",
      "6        6    112\n",
      "3        3     88\n",
      "Augmented train data shape: (7808, 6)\n",
      "Augmented train images shape: (32, 32, 3)\n",
      "Train data labels shape: (7808,)\n",
      "Raw test data shape: (1953, 6)\n",
      "Saving data...\n",
      "Saving train data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 244/244 [00:00<00:00, 1807.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means: [0.56824616 0.54440201 0.7644332 ]\n",
      "Stdevs: [0.16914784 0.15208819 0.14107539]\n",
      "Saving test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 62/62 [00:00<00:00, 2318.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means: [0.56845472 0.5446786  0.7624171 ]\n",
      "Stdevs: [0.16975521 0.15194911 0.14014961]\n",
      "Data preprocessing completed in 7.12 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from scripts.preprocessing import *\n",
    "\n",
    "preprocessor = DataProcessor(config_path='config.yaml')\n",
    "preprocessor.run(aug=False, rate = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# Step 2: Model building\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True, update_params=None):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    # Variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"Densenet121\":\n",
    "        weights = 'DEFAULT' if use_pretrained else None\n",
    "        model_ft = models.densenet121(weights=weights)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = config['preprocessing']['resize'][0]\n",
    "    \n",
    "    elif model_name == \"Resnet18\":\n",
    "        # Add initialization for Resnet18 if needed\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "    \n",
    "    # Update model parameters if update_params is provided\n",
    "    if update_params:\n",
    "        model_ft.load_state_dict(update_params)\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n",
    "# Step 3: Model training\n",
    "model_name = \"Densenet121\"\n",
    "num_classes = config['hyperparameters']['num_classes']\n",
    "feature_extract = config['hyperparameters']['feature_extract']\n",
    "use_pretrained = config['hyperparameters']['use_pretrained']\n",
    "\n",
    "# Example update_params dictionary\n",
    "update_params = {\n",
    "    # Add your parameter updates here\n",
    "}\n",
    "\n",
    "# Initialize the model for this run and move it to the device\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained, update_params)\n",
    "model = model_ft.to(device)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fxlqt\\AppData\\Local\\Temp\\ipykernel_14404\\798468676.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  encoder = torch.load(encoder_file)\n",
      "C:\\Users\\fxlqt\\AppData\\Local\\Temp\\ipykernel_14404\\798468676.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(data_file)\n"
     ]
    }
   ],
   "source": [
    "class HAM10000(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        # Load the merged data\n",
    "        data = torch.load(data_file)\n",
    "        self.images = data['images']\n",
    "        self.labels = data['data']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X = self.images[index]\n",
    "        y = torch.tensor(self.labels[index])\n",
    "        return X, y\n",
    "\n",
    "# Define location of prepared data\n",
    "size = config['preprocessing']['resize'][0]\n",
    "\n",
    "encoder_file = f'encoder/{size}x{size}.pt'\n",
    "train_data_file = f'data/processed/HAM10000_{size}x{size}_train.pt'\n",
    "test_data_file = f'data/processed/HAM10000_{size}x{size}_test.pt'\n",
    "\n",
    "# Load the encoder\n",
    "encoder = torch.load(encoder_file)\n",
    "\n",
    "# Load the training data\n",
    "train_data = HAM10000(train_data_file)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "# Load the test data\n",
    "test_data = HAM10000(test_data_file)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use Adam optimizer, use cross entropy loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_train, total_acc_train = [],[]\n",
    "def train(train_loader, model, criterion, optimizer, epoch, report_freq=100):\n",
    "    model.train()\n",
    "    train_loss = AverageMeter()\n",
    "    train_acc = AverageMeter()\n",
    "    curr_iter = (epoch - 1) * len(train_loader)\n",
    "    for i, data in enumerate(train_loader):\n",
    "        images, labels = data\n",
    "        N = images.size(0)\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        prediction = outputs.max(1, keepdim=True)[1]\n",
    "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "        train_loss.update(loss.item())\n",
    "        curr_iter += 1\n",
    "        if (i + 1) % report_freq == 0:\n",
    "            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (\n",
    "                epoch, i + 1, len(train_loader), train_loss.avg, train_acc.avg))\n",
    "            total_loss_train.append(train_loss.avg)\n",
    "            total_acc_train.append(train_acc.avg)\n",
    "    return train_loss.avg, train_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(test_loader, model, criterion, optimizer, epoch):\n",
    "    model.eval()\n",
    "    val_loss = AverageMeter()\n",
    "    val_acc = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            images, labels = data\n",
    "            N = images.size(0)\n",
    "            images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            prediction = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "            val_loss.update(criterion(outputs, labels).item())\n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    print('[epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, val_loss.avg, val_acc.avg))\n",
    "    print('------------------------------------------------------------')\n",
    "    return val_loss.avg, val_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...  on image size:  [32, 32]  with epoch:  10\n",
      "Training on epoch 1\n",
      "[epoch 1], [iter 100 / 244], [train loss 1.25884], [train acc 0.64781]\n",
      "[epoch 1], [iter 200 / 244], [train loss 1.21352], [train acc 0.66016]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 1.42997], [val acc 0.60484]\n",
      "------------------------------------------------------------\n",
      "*****************************************************\n",
      "best record: [epoch 1], [val loss 1.42997], [val acc 0.60484]\n",
      "*****************************************************\n",
      "Training on epoch 2\n",
      "[epoch 2], [iter 100 / 244], [train loss 1.21131], [train acc 0.66125]\n",
      "[epoch 2], [iter 200 / 244], [train loss 1.19989], [train acc 0.66344]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 1.25105], [val acc 0.64667]\n",
      "------------------------------------------------------------\n",
      "*****************************************************\n",
      "best record: [epoch 2], [val loss 1.25105], [val acc 0.64667]\n",
      "*****************************************************\n",
      "Training on epoch 3\n",
      "[epoch 3], [iter 100 / 244], [train loss 1.19531], [train acc 0.65719]\n",
      "[epoch 3], [iter 200 / 244], [train loss 1.18395], [train acc 0.66625]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 1.19755], [val acc 0.64315]\n",
      "------------------------------------------------------------\n",
      "Training on epoch 4\n",
      "[epoch 4], [iter 100 / 244], [train loss 1.19773], [train acc 0.66563]\n",
      "[epoch 4], [iter 200 / 244], [train loss 1.18977], [train acc 0.66406]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 1.55483], [val acc 0.63911]\n",
      "------------------------------------------------------------\n",
      "Training on epoch 5\n",
      "[epoch 5], [iter 100 / 244], [train loss 1.19380], [train acc 0.66156]\n",
      "[epoch 5], [iter 200 / 244], [train loss 1.16751], [train acc 0.67047]\n",
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 1.18520], [val acc 0.64667]\n",
      "------------------------------------------------------------\n",
      "Training on epoch 6\n",
      "[epoch 6], [iter 100 / 244], [train loss 1.20672], [train acc 0.66063]\n",
      "[epoch 6], [iter 200 / 244], [train loss 1.21502], [train acc 0.66484]\n",
      "------------------------------------------------------------\n",
      "[epoch 6], [val loss 1.22457], [val acc 0.64667]\n",
      "------------------------------------------------------------\n",
      "Training on epoch 7\n",
      "[epoch 7], [iter 100 / 244], [train loss 1.20167], [train acc 0.65812]\n",
      "[epoch 7], [iter 200 / 244], [train loss 1.17362], [train acc 0.66828]\n",
      "------------------------------------------------------------\n",
      "[epoch 7], [val loss 1.29623], [val acc 0.63760]\n",
      "------------------------------------------------------------\n",
      "Training on epoch 8\n",
      "[epoch 8], [iter 100 / 244], [train loss 1.22430], [train acc 0.65812]\n",
      "[epoch 8], [iter 200 / 244], [train loss 1.20871], [train acc 0.66047]\n",
      "------------------------------------------------------------\n",
      "[epoch 8], [val loss 1.26671], [val acc 0.64667]\n",
      "------------------------------------------------------------\n",
      "Training on epoch 9\n",
      "[epoch 9], [iter 100 / 244], [train loss 1.22492], [train acc 0.66094]\n",
      "[epoch 9], [iter 200 / 244], [train loss 1.19351], [train acc 0.66812]\n",
      "------------------------------------------------------------\n",
      "[epoch 9], [val loss 1.31860], [val acc 0.64667]\n",
      "------------------------------------------------------------\n",
      "Training on epoch 10\n",
      "[epoch 10], [iter 100 / 244], [train loss 1.17194], [train acc 0.66687]\n",
      "[epoch 10], [iter 200 / 244], [train loss 1.17912], [train acc 0.66453]\n",
      "------------------------------------------------------------\n",
      "[epoch 10], [val loss 1.39203], [val acc 0.64667]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 1\n",
    "# epoch_num = config['hyperparameters']['epochs']\n",
    "print('Start training...  on image size: ', config['preprocessing']['resize'], ' with epoch: ', epoch_num)\n",
    "best_val_acc = 0\n",
    "total_loss_val, total_acc_val = [],[]\n",
    "for epoch in range(1, epoch_num+1):\n",
    "    print('Training on epoch {}'.format(epoch))\n",
    "    loss_train, acc_train = train(train_loader, model, criterion, optimizer, epoch, report_freq=100)\n",
    "    loss_val, acc_val = validate(test_loader, model, criterion, optimizer, epoch)\n",
    "    total_loss_val.append(loss_val)\n",
    "    total_acc_val.append(acc_val)\n",
    "    if acc_val > best_val_acc:\n",
    "        best_val_acc = acc_val\n",
    "        print('*****************************************************')\n",
    "        print('Best record: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n",
    "        print('*****************************************************')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
